{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e095ebf9",
      "metadata": {},
      "source": [
        "# Submit Script to Azure Compute Cluster\n",
        "\n",
        "This notebook submits the `rerun_model.py` script to an Azure ML compute cluster for execution."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79101f16",
      "metadata": {},
      "source": [
        "## 1. Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "71a54265",
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml import command\n",
        "from azure.ai.ml.entities import Environment\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b52cb6e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "SCRIPT_NAME = 'rerun_model.py'\n",
        "CLUSTER_NAME = \"MLDevCluster2\" "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4674031b",
      "metadata": {},
      "source": [
        "## 2. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "03989a59",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Job name: Loonie-Bankuity-Model-Rerun-20251124-133611\n",
            "Using environment: autogluon-env:2\n"
          ]
        }
      ],
      "source": [
        "# Azure ML workspace configuration\n",
        "subscription_id = \"3ff01651-6d0f-4b11-b79c-7fa6ecbe432f\"\n",
        "resource_group = \"AnalysisSvcs_RG\"\n",
        "workspace_name = \"concorddevtestml_workspace\"\n",
        "\n",
        "# Compute cluster configuration\n",
        "compute_name = CLUSTER_NAME  # Replace with your compute cluster name\n",
        "\n",
        "# Environment configuration - specify pre-existing environment\n",
        "environment_name = \"autogluon-env\"  # Change this to your pre-existing environment\n",
        "environment_version = \"2\"  # Or specify version, use None for latest\n",
        "\n",
        "# Experiment configuration\n",
        "experiment_name = \"Loonie-Bankuity-Model-Rerun\"\n",
        "job_name = f\"{experiment_name}-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
        "\n",
        "print(f\"Job name: {job_name}\")\n",
        "print(f\"Using environment: {environment_name}:{environment_version}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa39f408",
      "metadata": {},
      "source": [
        "## 3. Initialize Azure ML Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fb99551f",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Class DeploymentTemplateOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connected to workspace: concorddevtestml_workspace\n"
          ]
        }
      ],
      "source": [
        "# Initialize the MLClient\n",
        "ml_client = MLClient(\n",
        "    DefaultAzureCredential(),\n",
        "    subscription_id=subscription_id,\n",
        "    resource_group_name=resource_group,\n",
        "    workspace_name=workspace_name,\n",
        ")\n",
        "\n",
        "print(f\"Connected to workspace: {workspace_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c30b270a",
      "metadata": {},
      "source": [
        "## 4. Use Pre-existing Environment\n",
        "\n",
        "Reference an existing environment from your Azure ML workspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "28053464",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using environment: azureml:autogluon-env:2\n"
          ]
        }
      ],
      "source": [
        "# Use pre-existing environment from the workspace\n",
        "if environment_version:\n",
        "    environment = f\"azureml:{environment_name}:{environment_version}\"\n",
        "else:\n",
        "    environment = f\"azureml:{environment_name}@latest\"\n",
        "\n",
        "print(f\"Using environment: {environment}\")\n",
        "\n",
        "# Alternative: Define a new environment (commented out)\n",
        "# environment = Environment(\n",
        "#     name=\"post-onboarding-env\",\n",
        "#     description=\"Environment for post-onboarding model comparison\",\n",
        "#     conda_file=\"../requirements.txt\",\n",
        "#     image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\"\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bc81952",
      "metadata": {},
      "source": [
        "## 5. Create Command Job\n",
        "\n",
        "Create the command job with proper source directory configuration. The script will load environment variables from the .env file automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "01ec315f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Command job created\n"
          ]
        }
      ],
      "source": [
        "from dotenv import dotenv_values\n",
        "env_local = dotenv_values(\".env\") \n",
        "# Create the command job\n",
        "job_env = {\n",
        "    \"DB_SERVER\": env_local[\"DB_SERVER\"],\n",
        "    \"DB_USER\": env_local[\"DB_USER\"],\n",
        "    \"DB_PASSWORD\": env_local[\"DB_PASSWORD\"],\n",
        "    \"ODBC_DRIVER_VERSION\": env_local.get(\"ODBC_DRIVER_VERSION\",\"ODBC Driver 18 for SQL Server\"),\n",
        "    \"DATAPATH\": \"ibv_status_data/loonie_ibv_shadowV3_dedup.csv\",\n",
        "    \"EXPERIMENT_NAME\": \"loonie_rerun_testV2\",\n",
        "    \"CLIENT_NAME\": \"Loonie\",\n",
        "    \"IBV_NAME\": \"LoonieIBV\",\n",
        "    \"TEST\": \"true\",\n",
        "    \"PARALLEL\": \"false\",\n",
        "    \"CONCURRENCY_LIMIT\": \"30\",\n",
        "    \"PYTHONPATH\": \".\"\n",
        "}\n",
        "job = command(\n",
        "    code=\".\",  # Point to src directory\n",
        "    command=f\"bash -lc \\\"apt-get update && ACCEPT_EULA=Y apt-get install -y msodbcsql18 unixodbc unixodbc-dev || true; pip install --no-input pyodbc SQLAlchemy; python {SCRIPT_NAME}\\\"\",\n",
        "    environment=environment,\n",
        "    compute=compute_name,\n",
        "    experiment_name=experiment_name,\n",
        "    display_name=job_name,\n",
        "    description=\"Run Bankuity model on Loonie IBV IDs\",\n",
        "    environment_variables=job_env,\n",
        "    #environment_variables={\n",
        "        \n",
        "        #\"PYTHONPATH\": \".\"  # Set PYTHONPATH to current directory (src) so run_test module can be found\n",
        "    #},\n",
        "    # Resource configuration\n",
        "    instance_count=1,\n",
        "    # Add timeout if needed (in seconds)\n",
        "    # timeout=7200,  # 2 hours\n",
        ")\n",
        "\n",
        "print(\"Command job created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87f23e47",
      "metadata": {},
      "source": [
        "## 6. Submit Job to Compute Cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ac4d70df",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "\u001b[32mUploading loonie_bankuity_rerun (1.02 MBs): 100%|██████████| 1022745/1022745 [00:00<00:00, 1950772.31it/s]\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Job submitted successfully!\n",
            "Job ID: modest_night_8fqtqndtkw\n",
            "Job Status: Starting\n",
            "Studio URL: https://ml.azure.com/runs/modest_night_8fqtqndtkw?wsid=/subscriptions/3ff01651-6d0f-4b11-b79c-7fa6ecbe432f/resourcegroups/AnalysisSvcs_RG/workspaces/concorddevtestml_workspace&tid=a0441342-388e-435c-a487-ed619a0af8d8\n"
          ]
        }
      ],
      "source": [
        "# Submit the job\n",
        "submitted_job = ml_client.jobs.create_or_update(job)\n",
        "\n",
        "print(\"Job submitted successfully!\")\n",
        "print(f\"Job ID: {submitted_job.name}\")\n",
        "print(f\"Job Status: {submitted_job.status}\")\n",
        "print(f\"Studio URL: {submitted_job.studio_url}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "184b3d49",
      "metadata": {},
      "source": [
        "## 7. Monitor Job Status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8c118d88",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current job status: Running\n",
            "Job details: Loonie-Bankuity-Model-Rerun-20251124-133611\n"
          ]
        }
      ],
      "source": [
        "# Get job status\n",
        "job_status = ml_client.jobs.get(submitted_job.name)\n",
        "print(f\"Current job status: {job_status.status}\")\n",
        "print(f\"Job details: {job_status.display_name}\")\n",
        "\n",
        "# You can also stream the logs\n",
        "# ml_client.jobs.stream(submitted_job.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a9b86b1",
      "metadata": {},
      "source": [
        "## 8. Optional: Stream Job Logs\n",
        "\n",
        "Uncomment the cell below to stream logs in real-time (this will block the cell until the job completes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8264a923",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stream job logs (this will block until job completes)\n",
        "# ml_client.jobs.stream(submitted_job.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73b8803e",
      "metadata": {},
      "source": [
        "## 9. Download Job Outputs (After Completion)\n",
        "\n",
        "After the job completes, you can download any outputs or logs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60724b9d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download job outputs after completion\n",
        "# ml_client.jobs.download(submitted_job.name, download_path=\"./job_outputs\")\n",
        "# print(\"Job outputs downloaded to ./job_outputs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2776b8a",
      "metadata": {},
      "source": [
        "## 10. Job Management Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fb4500a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# List recent jobs in the experiment\n",
        "jobs = ml_client.jobs.list(max_results=10)\n",
        "print(\"Recent jobs:\")\n",
        "for job in jobs:\n",
        "    print(f\"  {job.name}: {job.status} - {job.display_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "026b551f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cancel a job if needed (uncomment and provide job name)\n",
        "# job_to_cancel = \"job-name-here\"\n",
        "# ml_client.jobs.cancel(job_to_cancel)\n",
        "# print(f\"Job {job_to_cancel} cancelled\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05f209e0",
      "metadata": {},
      "source": [
        "## Notes\n",
        "\n",
        "1. **Environment Setup**: Make sure your compute cluster has access to the required packages (pandas, sqlalchemy, pyodbc, etc.)\n",
        "\n",
        "2. **Database Access**: Ensure the compute cluster can access your SQL Server database. You may need to configure network access or use Azure Key Vault for credentials.\n",
        "\n",
        "3. **File Access**: Make sure the CSV file specified in `CSV_FILE_PATH` is accessible to the compute cluster.\n",
        "\n",
        "4. **Environment Variables**: Update the configuration section with your actual values for experiment name, client name, etc.\n",
        "\n",
        "5. **Resource Requirements**: Adjust the compute cluster size based on your data size and processing requirements.\n",
        "\n",
        "6. **Monitoring**: Use the Azure ML Studio URL to monitor job progress and view detailed logs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4836e77",
      "metadata": {},
      "source": [
        "## 11. Create New Environment (Optional)\n",
        "\n",
        "Use this cell to create a new environment based on requirements.txt if you don't have a pre-existing environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1962242",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment created: post-onboarding-env-custom:2\n",
            "Conda.yml file has been created at ../conda.yml\n",
            "Uncomment the code above to create the environment from conda.yml\n"
          ]
        }
      ],
      "source": [
        "# Create a new environment based on conda.yml\n",
        "# Uncomment and run this cell if you need to create a new environment\n",
        "\n",
        "\n",
        "new_environment = Environment(\n",
        "    name=\"post-onboarding-env-custom\",\n",
        "    description=\"Custom environment for post-onboarding model comparison created from conda.yml\",\n",
        "    conda_file=\"../conda.yml\",  # Path to conda.yml file in src directory\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\"\n",
        ")\n",
        "\n",
        "# Create the environment in the workspace\n",
        "created_env = ml_client.environments.create_or_update(new_environment)\n",
        "print(f\"Environment created: {created_env.name}:{created_env.version}\")\n",
        "\n",
        "# To use this new environment, update the configuration in cell 2:\n",
        "# environment_name = \"post-onboarding-env-custom\"\n",
        "# environment_version = created_env.version\n",
        "\n",
        "print(\"Conda.yml file has been created at ../conda.yml\")\n",
        "print(\"Uncomment the code above to create the environment from conda.yml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65bd7dc0",
      "metadata": {},
      "source": [
        "## Download Job Outputs (After Completion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96403027",
      "metadata": {},
      "outputs": [],
      "source": [
        "ml_client.jobs.download(\n",
        "    name=\"lucid_sail_3cf8ld23v3\",\n",
        "    output_name=\"default\",        # or your named output (e.g., \"model\", \"score\")\n",
        "    download_path=\"outputs\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
